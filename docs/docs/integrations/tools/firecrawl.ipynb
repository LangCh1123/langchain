{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firecrawl Website Scraping Tool\n",
    "\n",
    "This notebook demonstrates how to use the `FirecrawlScrapeWebsiteTool` to scrape websites and extract markdown content. The tool leverages the Firecrawl API to map and scrape URLs from a given base URL.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Firecrawl API Key**: You need an API key to access the Firecrawl service. You can obtain this by signing up on the Firecrawl platform.\n",
    "\n",
    "2. **Environment Setup**: Ensure that the `FIRECRAWL_API_KEY` environment variable is set with your API key. You can also pass the API key directly when initializing the tool.\n",
    "\n",
    "3. **Python Environment**: Make sure you have Python installed along with the necessary packages. You can install the required packages using:\n",
    "\n",
    "   ```bash\n",
    "   pip install firecrawl-py langchain-core langchain-openai\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "from firecrawl import FirecrawlApp\n",
    "from langchain_community.tools.firecrawl.tool import FirecrawlScrapeWebsiteTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Tool\n",
    "\n",
    "### Initialize the Tool\n",
    "\n",
    "Create an instance of the `FirecrawlScrapeWebsiteTool`. You can specify the API key and whether to limit the scraping rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_tool = FirecrawlScrapeWebsiteTool(api_key=\"your_api_key\", limit_rate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, set the `FIRECRAWL_API_KEY` environment variable and initialize the tool without parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"FIRECRAWL_API_KEY\"] = \"your_api_key\"\n",
    "scrape_tool = FirecrawlScrapeWebsiteTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Tool\n",
    "\n",
    "### Synchronous Scraping\n",
    "\n",
    "To scrape a website synchronously, use the `_run` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://example.com\"\n",
    "markdown_content = scrape_tool._run(base_url)\n",
    "print(markdown_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous Scraping\n",
    "\n",
    "For asynchronous scraping, use the `_arun` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def scrape_website_async():\n",
    "    base_url = \"https://example.com\"\n",
    "    markdown_content = await scrape_tool._arun(base_url)\n",
    "    print(markdown_content)\n",
    "\n",
    "\n",
    "asyncio.run(scrape_website_async())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using with Agents\n",
    "\n",
    "The `FirecrawlScrapeWebsiteTool` can be integrated with agents to automate the scraping process as part of a larger workflow. Here's how you can set it up:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.agents import initialize_agent, AgentType\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Initialize the language model\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# Create an agent with the Firecrawl tool\n",
    "agent = initialize_agent(\n",
    "    tools=[scrape_tool],\n",
    "    llm=llm,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Run the agent with a task\n",
    "result = agent.run(\n",
    "    \"Scrape the website at https://example.com and extract markdown content.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Output\n",
    "\n",
    "The tool returns markdown content extracted from the website. Each URL's content is prefixed with a header indicating the URL, followed by the markdown content, and separated by a line of dashes.\n",
    "\n",
    "## Error Handling\n",
    "\n",
    "The tool includes error handling for mapping and scraping URLs. If an error occurs, it logs the error and raises a `RuntimeError`.\n",
    "\n",
    "## Logging\n",
    "\n",
    "The tool uses Python's logging module to provide information about the scraping process, including rate limiting and any warnings or errors encountered.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The `FirecrawlScrapeWebsiteTool` is a powerful utility for extracting markdown content from websites. By following the steps outlined in this guide, you can effectively use the tool to scrape and process web content."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
