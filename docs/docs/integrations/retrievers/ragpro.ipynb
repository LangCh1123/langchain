{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAGProRetriever\n",
    "\n",
    "## Overview\n",
    "This retriever allows you to filter your search by domain and provides higher quality results than just chunks of context; meaning that the need to perform Corrective RAG or worry about low-quality data is gone.\n",
    "\n",
    "Instead, this retriever uses a search engine to find relevant documents with an LLM to provide your RAG app with the highest quality data possible.\n",
    "\n",
    "We are also the first retriever to support url (domain) filtering which means you no longer need to scrape and index specific sites yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (0.3.2)\n",
      "Requirement already satisfied: langchain in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (0.3.3)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-community) (0.1.134)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-community) (2.0.35)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-community) (2.5.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-community) (3.10.10)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.10 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-community) (0.3.10)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.15.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (24.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.7)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: anyio in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.6.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade langchain-community langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get your api key [here](https://docs.rag.pro/account)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import RAGProRetriever\n",
    "\n",
    "retriever = RAGProRetriever(\n",
    "    api_key=\"RAG-PRO-API-KEY\",\n",
    "    # Choose between small, medium, or large model sizes depending on your use case\n",
    "    model=\"small\",\n",
    "    include_sources=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1:\n",
      "To create a ReAct agent graph using OpenAI as the Large Language Model (LLM) in LangGraph, you can follow these steps:\n",
      "\n",
      "## Install Required Packages\n",
      "Ensure you have the necessary packages installed. You can do this using the following command:\n",
      "\n",
      "```python\n",
      "%pip install -U langgraph langchain-openai\n",
      "```\n",
      "\n",
      "## Set Up API Keys\n",
      "Set your OpenAI API key as an environment variable:\n",
      "\n",
      "```python\n",
      "import getpass\n",
      "import os\n",
      "\n",
      "def _set_env(var: str):\n",
      "    if not os.environ.get(var):\n",
      "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
      "\n",
      "_set_env(\"OPENAI_API_KEY\")\n",
      "```\n",
      "\n",
      "## Initialize the Model\n",
      "Initialize the OpenAI model you want to use:\n",
      "\n",
      "```python\n",
      "from langchain_openai import ChatOpenAI\n",
      "\n",
      "model = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
      "```\n",
      "\n",
      "## Define Tools (Optional)\n",
      "If you want to use tools with your agent, define them using the `@tool` decorator:\n",
      "\n",
      "```python\n",
      "from typing import Literal\n",
      "from langchain_core.tools import tool\n",
      "\n",
      "@tool\n",
      "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
      "    \"\"\"Use this to get weather information.\"\"\"\n",
      "    if city == \"nyc\":\n",
      "        return \"It might be cloudy in nyc\"\n",
      "    elif city == \"sf\":\n",
      "        return \"It's always sunny in sf\"\n",
      "    else:\n",
      "        raise AssertionError(\"Unknown city\")\n",
      "\n",
      "tools = [get_weather]\n",
      "```\n",
      "\n",
      "## Create the ReAct Agent Graph\n",
      "You can either create the graph from scratch or use the prebuilt `create_react_agent` function. Here is how to do it using the prebuilt function:\n",
      "\n",
      "```python\n",
      "from langgraph.prebuilt import create_react_agent\n",
      "\n",
      "graph = create_react_agent(model, tools=tools)\n",
      "```\n",
      "\n",
      "### Creating from Scratch\n",
      "If you prefer to create the graph from scratch, here is an example:\n",
      "\n",
      "```python\n",
      "from langgraph.graph import StateGraph, END\n",
      "from langchain_core.messages import BaseMessage\n",
      "from langgraph.graph.message import add_messages\n",
      "from typing import Annotated, Sequence, TypedDict\n",
      "\n",
      "class AgentState(TypedDict):\n",
      "    \"\"\"The state of the agent.\"\"\"\n",
      "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
      "\n",
      "workflow = StateGraph(AgentState)\n",
      "\n",
      "# Define the nodes\n",
      "workflow.add_node(\"agent\", model)\n",
      "workflow.add_node(\"tools\", ToolNode(tools))\n",
      "\n",
      "# Set the entry point\n",
      "workflow.set_entry_point(\"agent\")\n",
      "\n",
      "# Define conditional edges\n",
      "def should_continue(state):\n",
      "    # Implement logic to decide whether to continue or end\n",
      "    # For example:\n",
      "    last_message = state[\"messages\"][-1]\n",
      "    if \"tool\" in last_message.content:\n",
      "        return \"continue\"\n",
      "    else:\n",
      "        return \"end\"\n",
      "\n",
      "workflow.add_conditional_edges(\n",
      "    \"agent\",\n",
      "    should_continue,\n",
      "    {\n",
      "        \"continue\": \"tools\",\n",
      "        \"end\": END,\n",
      "    }\n",
      ")\n",
      "\n",
      "# Add edge from tools to agent\n",
      "workflow.add_edge(\"tools\", \"agent\")\n",
      "\n",
      "# Compile the graph\n",
      "graph = workflow.compile()\n",
      "```\n",
      "\n",
      "## Visualize and Use the Graph\n",
      "You can visualize the graph and use it to process inputs:\n",
      "\n",
      "```python\n",
      "from IPython.display import Image, display\n",
      "\n",
      "display(Image(graph.get_graph().draw_mermaid_png()))\n",
      "\n",
      "def print_stream(stream):\n",
      "    for s in stream:\n",
      "        message = s[\"messages\"][-1]\n",
      "        if isinstance(message, tuple):\n",
      "            print(message)\n",
      "        else:\n",
      "            message.pretty_print()\n",
      "\n",
      "inputs = {\"messages\": [(\"user\", \"what is the weather in sf\")]}\n",
      "print_stream(graph.stream(inputs, stream_mode=\"values\"))\n",
      "```\n",
      "\n",
      "This setup allows you to create a ReAct agent using OpenAI as the LLM and integrate tools if necessary, all within the LangGraph framework[2][4][5].\n",
      "Source: ['https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/', 'https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/', 'https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-memory/', 'https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/', 'https://python.langchain.com/docs/how_to/migrate_agent/']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define your query and source filter\n",
    "query = \"How can I create a react agent graph with openai as the llm?\"\n",
    "source_filter = [\"https://python.langchain.com/api_reference/\", \"https://langchain-ai.github.io/langgraph/#example\"]\n",
    "\n",
    "# Retrieve documents\n",
    "docs = retriever.get_relevant_documents(query, urls=source_filter)\n",
    "\n",
    "# Print the full content of each document\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content)  # This will print the entire content\n",
    "    print(f\"Sources: {doc.metadata.get('source', 'Not available')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use within a chain\n",
    "Like other retrievers, `RAGProRetriever` can be integrated into LLM applications via chains.\n",
    "\n",
    "We will need a LLM or chat model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Using cached langchain_openai-0.2.2-py3-none-any.whl (49 kB)\n",
      "Collecting openai<2.0.0,>=1.40.0\n",
      "  Using cached openai-1.51.2-py3-none-any.whl (383 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.9 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-openai) (0.3.10)\n",
      "Collecting tiktoken<1,>=0.7\n",
      "  Using cached tiktoken-0.8.0-cp310-cp310-macosx_11_0_arm64.whl (982 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (24.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (2.9.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (1.33)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (8.5.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-openai) (0.1.134)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.27.2)\n",
      "Collecting tqdm>4\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.6.2)\n",
      "Requirement already satisfied: sniffio in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Using cached jiter-0.6.1-cp310-cp310-macosx_11_0_arm64.whl (301 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Collecting regex>=2022.1.18\n",
      "  Using cached regex-2024.9.11-cp310-cp310-macosx_11_0_arm64.whl (284 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.9->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.9->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.9->langchain-openai) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.9->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.9->langchain-openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n",
      "Installing collected packages: tqdm, regex, jiter, distro, tiktoken, openai, langchain-openai\n",
      "Successfully installed distro-1.9.0 jiter-0.6.1 langchain-openai-0.2.2 openai-1.51.2 regex-2024.9.11 tiktoken-0.8.0 tqdm-4.66.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Chain with Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a ReAct agent graph using OpenAI as the Large Language Model (LLM), follow these steps:\n",
      "\n",
      "1. **Setup and Dependencies**: Install the necessary packages and set up your OpenAI API key.\n",
      "   ```bash\n",
      "   %pip install -U langgraph langchain-openai\n",
      "   ```\n",
      "\n",
      "   ```python\n",
      "   import getpass\n",
      "   import os\n",
      "\n",
      "   def _set_env(var: str):\n",
      "       if not os.environ.get(var):\n",
      "           os.environ[var] = getpass.getpass(f\"{var}: \")\n",
      "\n",
      "   _set_env(\"OPENAI_API_KEY\")\n",
      "   ```\n",
      "\n",
      "2. **Define the Model and Tools**: Load the OpenAI chat model and define any tools you want to use.\n",
      "   ```python\n",
      "   from langchain_openai import ChatOpenAI\n",
      "   from langchain_core.tools import tool\n",
      "\n",
      "   model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
      "\n",
      "   @tool\n",
      "   def get_weather(city: str):\n",
      "       \"\"\"Use this to get weather information.\"\"\"\n",
      "       if city == \"nyc\":\n",
      "           return \"It might be cloudy in nyc\"\n",
      "       elif city == \"sf\":\n",
      "           return \"It's always sunny in sf\"\n",
      "       else:\n",
      "           raise AssertionError(\"Unknown city\")\n",
      "\n",
      "   tools = [get_weather]\n",
      "   ```\n",
      "\n",
      "3. **Define the Graph State**: Create the state of your agent, which includes a list of messages.\n",
      "   ```python\n",
      "   from typing import Annotated, Sequence, TypedDict\n",
      "   from langchain_core.messages import BaseMessage\n",
      "   from langgraph.graph.message import add_messages\n",
      "\n",
      "   class AgentState(TypedDict):\n",
      "       \"\"\"The state of the agent.\"\"\"\n",
      "       messages: Annotated[Sequence[BaseMessage], add_messages]\n",
      "   ```\n",
      "\n",
      "4. **Define Nodes and Edges**: Create nodes for the agent and tools, and set up the edges to control the flow of the graph.\n",
      "   ```python\n",
      "   from langgraph.graph import StateGraph, END\n",
      "   from langgraph.prebuilt import ToolNode\n",
      "\n",
      "   # Define a new graph\n",
      "   workflow = StateGraph(AgentState)\n",
      "\n",
      "   # Define the tool node\n",
      "   tool_node = ToolNode(tools)\n",
      "\n",
      "   # Define the nodes\n",
      "   workflow.add_node(\"agent\", model)\n",
      "   workflow.add_node(\"tools\", tool_node)\n",
      "\n",
      "   # Set the entry point as `agent`\n",
      "   workflow.set_entry_point(\"agent\")\n",
      "\n",
      "   # Add conditional edges\n",
      "   def should_continue(state):\n",
      "       return \"continue\" if \"tool_call\" in state[\"messages\"][-1].content else \"end\"\n",
      "\n",
      "   workflow.add_conditional_edges(\n",
      "       \"agent\",\n",
      "       should_continue,\n",
      "       {\"continue\": \"tools\", \"end\": END}\n",
      "   )\n",
      "\n",
      "   # Add a normal edge from `tools` to `agent`\n",
      "   workflow.add_edge(\"tools\", \"agent\")\n",
      "\n",
      "   # Compile the graph\n",
      "   graph = workflow.compile()\n",
      "   ```\n",
      "\n",
      "5. **Use the ReAct Agent**: Process inputs and stream the results.\n",
      "   ```python\n",
      "   def print_stream(stream):\n",
      "       for s in stream:\n",
      "           message = s[\"messages\"][-1]\n",
      "           if isinstance(message, tuple):\n",
      "               print(message)\n",
      "           else:\n",
      "               message.pretty_print()\n",
      "\n",
      "   inputs = {\"messages\": [(\"user\", \"what is the weather in sf\")]}\n",
      "   print_stream(graph.stream(inputs, stream_mode=\"values\"))\n",
      "   ```\n",
      "\n",
      "This setup allows you to create a ReAct agent graph using OpenAI as the LLM.\n",
      "\n",
      "Sources:\n",
      "https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-hitl/\n",
      "https://python.langchain.com/docs/how_to/migrate_agent/\n",
      "https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/\n",
      "https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/\n",
      "https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the question based only on the context provided.\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def format_sources(docs):\n",
    "    sources = []\n",
    "    for doc in docs:\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        if isinstance(source, list):\n",
    "            sources.extend(source)\n",
    "        else:\n",
    "            sources.append(source)\n",
    "    return \"\\n\".join(set(sources))\n",
    "\n",
    "def retrieve_with_sources(inputs):\n",
    "    query = inputs[\"question\"]\n",
    "    urls = inputs.get(\"urls\", None)\n",
    "    return retriever.get_relevant_documents(query, urls=urls)\n",
    "\n",
    "def process_llm_response(inputs):\n",
    "    llm_response = inputs[\"llm_response\"]\n",
    "    sources = inputs[\"sources\"]\n",
    "    return f\"{llm_response}\\n\\nSources:\\n{sources}\"\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough()\n",
    "    | {\n",
    "        \"context\": RunnableLambda(retrieve_with_sources) | RunnableLambda(format_docs),\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"sources\": RunnableLambda(retrieve_with_sources) | RunnableLambda(format_sources)\n",
    "    }\n",
    "    | {\n",
    "        \"llm_response\": (lambda x: {\"context\": x[\"context\"], \"question\": x[\"question\"]}) | prompt | llm | StrOutputParser(),\n",
    "        \"sources\": lambda x: x[\"sources\"]\n",
    "    }\n",
    "    | RunnableLambda(process_llm_response)\n",
    ")\n",
    "\n",
    "# Example usage of the chain with filtered sources\n",
    "result = chain.invoke({\n",
    "    \"question\": \"How can I create a react agent graph with openai as the llm?\",\n",
    "    \"urls\": [\"https://python.langchain.com/api_reference/\", \"https://langchain-ai.github.io/langgraph/#example\"]\n",
    "})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agentic RAG with RAG Pro Retriever\n",
    "\n",
    "Taken from this [Notebook](https://github.com/langchain-ai/langchain/blob/master/cookbook/langgraph_agentic_rag.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (0.2.35)\n",
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.2.39 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langgraph) (0.3.10)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langgraph) (2.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchainhub) (24.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchainhub) (2.32.3)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2\n",
      "  Downloading types_requests-2.32.0.20240914-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (1.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (2.9.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (0.1.134)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (8.5.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (2.2.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.2.39->langgraph) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (1.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (0.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.2.39->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.2.39->langgraph) (2.23.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (1.3.1)\n",
      "Requirement already satisfied: anyio in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (4.6.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/seansullivan/langchain-1/venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (1.2.2)\n",
      "Installing collected packages: types-requests, langchainhub\n",
      "Successfully installed langchainhub-0.1.21 types-requests-2.32.0.20240914\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langgraph langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    Annotated,\n",
    "    Sequence,\n",
    "    TypedDict,\n",
    ")\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"The state of the agent.\"\"\"\n",
    "\n",
    "    # add_messages is a reducer\n",
    "    # See https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "@tool\n",
    "def search_langchain(query: str, urls: Optional[List[str]] = None):\n",
    "    \"\"\"\n",
    "    Agent with access to up-to-date information from Langchain and Langgraph's python examples, documentation, and guides.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query.\n",
    "        urls (Optional[List[str]]): List of URLs to filter the search results.\n",
    "                                    If not provided, the search will not be filtered by URL.\n",
    "    \"\"\"\n",
    "    return retriever.get_relevant_documents(query, urls=['https://python.langchain.com/docs/', 'https://langchain-ai.github.io/'])\n",
    "\n",
    "\n",
    "tools = [search_langchain]\n",
    "\n",
    "model = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "graph = create_react_agent(model, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Create a Math expert react agent graph with openai as the llm that breaks down user's math queries into smaller steps and uses python/calculator tools to accomplish them\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_langchain (call_uUDgcUy6KPSvCpPj4Lw8vlfw)\n",
      " Call ID: call_uUDgcUy6KPSvCpPj4Lw8vlfw\n",
      "  Args:\n",
      "    query: Math expert react agent graph with OpenAI LLM\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_langchain\n",
      "\n",
      "[Document(metadata={'source': ['https://python.langchain.com/docs/additional_resources/arxiv_references/', 'https://python.langchain.com/docs/integrations/llms/google_vertex_ai_palm/', 'https://python.langchain.com/docs/integrations/document_transformers/markdownify/']}, page_content='To create a math expert React agent graph using OpenAI\\'s LLM, you can leverage the concepts and tools discussed in the LangChain documentation and the ReAct paper. Here’s a step-by-step guide to integrate this:\\n\\n1. **Understand ReAct**: The ReAct approach involves generating both reasoning traces and task-specific actions in an interleaved manner. This allows the model to induce, track, and update action plans while handling exceptions, and it can interface with external sources like knowledge bases or environments to gather additional information[1].\\n\\n2. **Integrate with OpenAI LLM**: You can use OpenAI\\'s GPT-4 model, which is known for its strong language capabilities, to serve as the core controller in your agent. This involves using the GPT-4 model to conduct task planning, select appropriate AI models, execute each subtask, and summarize the response based on execution results[1].\\n\\n3. **Implementing Math Expertise**:\\n   - **Reasoning Traces**: For math problems, you can generate reasoning traces that include step-by-step solutions. This helps in making the model more interpretable and trustworthy.\\n   - **External Tools**: You might need to integrate external tools or APIs for specific mathematical operations, such as calling a calculator API for arithmetic tasks. This integration can be done using tool-augmented language models (TALM) or toolformers, which fine-tune LLMs to learn using external tool APIs[3].\\n\\n4. **Example Code**:\\n   - **Setting Up the Environment**: Ensure you have the necessary packages installed, such as `langchain-google-vertexai` for integrating with Google Cloud models, and `langchain` for general LLM integration.\\n   - **Using GPT-4**: You can invoke GPT-4 using the `langchain-google-vertexai` package to generate responses to mathematical queries.\\n   - **Example Code Snippet**:\\n     ```python\\n     from langchain_google_vertexai import VertexAI\\n\\n     # Initialize the GPT-4 model\\n     model = VertexAI(model_name=\"gpt-4\")\\n\\n     # Define a math problem\\n     math_problem = \"Solve for x in the equation 2x + 5 = 11\"\\n\\n     # Generate the solution\\n     solution = model.invoke(math_problem)\\n\\n     # Print the solution\\n     print(solution)\\n     ```\\n\\n5. **Enhancing with ReAct**:\\n   - **Generate Reasoning Traces**: Use ReAct to generate reasoning traces for the math problem. This involves creating a sequence of steps that lead to the solution.\\n   - **Integrate with External Tools**: If necessary, integrate with external tools like a calculator API to perform specific arithmetic operations.\\n\\nBy following these steps, you can create a math expert React agent graph that leverages OpenAI\\'s LLM capabilities and integrates with external tools as needed.')]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To create a Math expert React agent graph using OpenAI's LLM that breaks down user math queries into smaller steps and utilizes Python/calculator tools, follow these steps:\n",
      "\n",
      "### Step-by-Step Guide\n",
      "\n",
      "1. **Understand ReAct Approach**: \n",
      "   - The ReAct framework allows the model to generate reasoning traces and perform tasks in an interleaved manner. This helps in tracking action plans and handling exceptions while interacting with external resources.\n",
      "\n",
      "2. **Integrate with OpenAI LLM**:\n",
      "   - Use OpenAI's GPT-4 model as the core controller. This will involve using the model for task planning, selecting suitable actions, executing subtasks, and summarizing results.\n",
      "\n",
      "3. **Implementing Math Expertise**:\n",
      "   - **Reasoning Traces**: Create step-by-step reasoning for math problems to enhance interpretability and trust.\n",
      "   - **External Tools**: Integrate APIs for specific calculations. For example, using a calculator API for arithmetic tasks.\n",
      "\n",
      "4. **Example Code**:\n",
      "   - **Setting Up the Environment**: Install necessary packages like `langchain` and any needed for API integration.\n",
      "   - **Using GPT-4**: Here’s a simple example code snippet to invoke the GPT-4 model:\n",
      "\n",
      "     ```python\n",
      "     from langchain_google_vertexai import VertexAI\n",
      "\n",
      "     # Initialize the GPT-4 model\n",
      "     model = VertexAI(model_name=\"gpt-4\")\n",
      "\n",
      "     # Define a math problem\n",
      "     math_problem = \"Solve for x in the equation 2x + 5 = 11\"\n",
      "\n",
      "     # Generate the solution\n",
      "     solution = model.invoke(math_problem)\n",
      "\n",
      "     # Print the solution\n",
      "     print(solution)\n",
      "     ```\n",
      "\n",
      "5. **Enhancing with ReAct**:\n",
      "   - Implement the generation of reasoning traces for the math problem to outline the steps leading to the solution.\n",
      "   - If needed, leverage external tools (like a calculator API) to perform specific operations.\n",
      "\n",
      "### Example Implementation\n",
      "\n",
      "- **User Input**: The user asks a math question (e.g., \"What is the integral of x^2?\").\n",
      "- **Break it Down**: The OpenAI LLM identifies smaller steps (like finding the derivative, applying integration rules, etc.).\n",
      "- **Use Python Tools**: The agent uses a Python tool or a calculator API to perform calculations.\n",
      "- **Output**: Finally, the agent summarizes the result and explains the reasoning behind each step.\n",
      "\n",
      "By following this guide, you can successfully create a Math expert React agent that effectively assists users with their mathematical queries, providing clear and structured solutions.\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [(\"user\", \"Create a Math expert react agent graph with openai as the llm that breaks down user's math queries into smaller steps and uses python/calculator tools to accomplish them\")]}\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all `RAGProRetriever` features and configurations, refer to the [API reference](https://docs.rag.pro/documentation).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
