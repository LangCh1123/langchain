{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlines\n",
    "\n",
    "This page covers how to use LangChain with Outlines models. It is broken into two parts: installation and setup, and then usage.\n",
    "\n",
    "## Installation\n",
    "\n",
    "To use Outlines with LangChain, you need to install the `outlines` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install outlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, you need to import the Outlines LLM class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Outlines\n",
    "\n",
    "# For use with llamacpp backend\n",
    "model = Outlines(model=\"microsoft/Phi-3-mini-4k-instruct\", backend=\"llamacpp\")\n",
    "\n",
    "# For use with vllm backend (not available on Mac)\n",
    "model = Outlines(model=\"microsoft/Phi-3-mini-4k-instruct\", backend=\"vllm\")\n",
    "\n",
    "# For use with mlxlm backend (only available on Mac)\n",
    "model = Outlines(model=\"microsoft/Phi-3-mini-4k-instruct\", backend=\"mlxlm\")\n",
    "\n",
    "# For use with huggingface transformers backend\n",
    "model = Outlines(\n",
    "    model=\"microsoft/Phi-3-mini-4k-instruct\"\n",
    ")  # defaults to backend=\"transformers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "### Text Generation\n",
    "You can use the Outlines model for simple text generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.outlines import Outlines\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's approach this step-by-step:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | model\n",
    "response = chain.invoke({\"question\": \"What is Outlines?\"})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming\n",
    "\n",
    "Outlines supports streaming of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in model.stream(\"Count to 10 in French:\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrained Generation\n",
    "\n",
    "Outlines allows you to apply various constraints to the generated output:\n",
    "\n",
    "#### Regex Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.regex = r\"((25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\"\n",
    "response = model.invoke(\"What is the IP address of Google's DNS server?\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.type_constraints = int\n",
    "response = model.invoke(\"What is the answer to life, the universe, and everything?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "\n",
    "\n",
    "model.json_schema = Person\n",
    "response = model.invoke(\"Who is the author of LangChain?\")\n",
    "person = Person.model_validate_json(response)\n",
    "\n",
    "person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grammar Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.grammar = \"\"\"\n",
    "?start: expression\n",
    "?expression: term ((\"+\" | \"-\") term)\n",
    "?term: factor ((\"\" | \"/\") factor)\n",
    "?factor: NUMBER | \"-\" factor | \"(\" expression \")\"\n",
    "%import common.NUMBER\n",
    "%import common.WS\n",
    "%ignore WS\n",
    "\"\"\"\n",
    "response = model.invoke(\"Give me a complex arithmetic expression:\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Outlines Documentation: \n",
    "\n",
    "https://dottxt-ai.github.io/outlines/latest/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
